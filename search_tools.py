import asyncio
import aiohttp
from typing import List, Dict, Optional, Tuple
import json
from datetime import datetime
import hashlib

class MetaSearchEngine:
    def __init__(self, search_apis: Dict[str, dict], cache_enabled: bool = True):
        """
        å…ƒæœç´¢å¼•æ“
        
        å‚æ•°:
            search_apis: æœç´¢å¼•æ“é…ç½®å­—å…¸
            cache_enabled: æ˜¯å¦å¯ç”¨ç»“æœç¼“å­˜
        """
        self.search_apis = search_apis
        self.timeout = 10
        self.session = None
        self.cache_enabled = cache_enabled
        self.result_cache = {}
        
    async def initialize(self):
        """åˆå§‹åŒ–aiohttpä¼šè¯"""
        self.session = aiohttp.ClientSession()

    async def close(self):
        """å…³é—­aiohttpä¼šè¯"""
        if self.session:
            await self.session.close()

    def _get_cache_key(self, query: str) -> str:
        """ç”Ÿæˆç¼“å­˜é”®"""
        return hashlib.md5(query.encode('utf-8')).hexdigest()

    async def _fetch_from_engine(self, engine: str, query: str, num_results: int) -> Tuple[str, List[Dict]]:
        """ä»å•ä¸ªå¼•æ“è·å–ç»“æœ"""
        if not self.session:
            await self.initialize()

        api_config = self.search_apis.get(engine)
        if not api_config:
            return engine, []

        params = {
            "q": query,
            "api_key": api_config["api_key"],
            "num": num_results
        }

        try:
            async with self.session.get(
                api_config["endpoint"],
                params=params,
                timeout=aiohttp.ClientTimeout(total=self.timeout)
            ) as response:
                
                if response.status == 200:
                    results = await response.json()
                    return engine, self._normalize_results(engine, results)
                return engine, []
                
        except Exception as e:
            print(f"{engine}æœç´¢å‡ºé”™: {str(e)}")
            return engine, []

    def _normalize_results(self, engine: str, results: Dict) -> List[Dict]:
        """æ ‡å‡†åŒ–ä¸åŒå¼•æ“çš„ç»“æœæ ¼å¼"""
        normalized = []
        
        if engine == "google":
            for item in results.get("organic_results", []):
                normalized.append({
                    "title": item.get("title", ""),
                    "link": item.get("link", ""),
                    "snippet": item.get("snippet", ""),
                    "source": "Google",
                    "score": self._calculate_relevance(item)
                })
        elif engine == "bing":
            for item in results.get("webPages", {}).get("value", []):
                normalized.append({
                    "title": item.get("name", ""),
                    "link": item.get("url", ""),
                    "snippet": item.get("snippet", ""),
                    "source": "Bing",
                    "score": self._calculate_relevance(item)
                })
        elif engine == "duckduckgo":
            for item in results.get("results", []):
                normalized.append({
                    "title": item.get("title", ""),
                    "link": item.get("link", ""),
                    "snippet": item.get("description", ""),
                    "source": "DuckDuckGo",
                    "score": self._calculate_relevance(item)
                })
                
        return normalized[:5]  # æ¯ä¸ªå¼•æ“æœ€å¤šè¿”å›5æ¡ç»“æœ

    def _calculate_relevance(self, item: Dict) -> float:
        """è®¡ç®—ç»“æœç›¸å…³æ€§åˆ†æ•°"""
        title_len = len(item.get("title", ""))
        snippet_len = len(item.get("snippet", ""))
        return (title_len * 0.6 + snippet_len * 0.4) / 100

    async def meta_search(self, query: str, num_results: int = 5) -> List[Dict]:
        """
        æ‰§è¡Œå…ƒæœç´¢
        
        å‚æ•°:
            query: æœç´¢æŸ¥è¯¢
            num_results: æœŸæœ›è¿”å›çš„ç»“æœæ•°é‡
            
        è¿”å›:
            æ•´åˆã€å»é‡å’Œæ’åºåçš„ç»“æœåˆ—è¡¨
        """
        # æ£€æŸ¥ç¼“å­˜
        cache_key = self._get_cache_key(query)
        if self.cache_enabled and cache_key in self.result_cache:
            return self.result_cache[cache_key][:num_results]

        # å¹¶è¡ŒæŸ¥è¯¢æ‰€æœ‰å¼•æ“
        tasks = [self._fetch_from_engine(engine, query, num_results) 
                for engine in self.search_apis.keys()]
        results = await asyncio.gather(*tasks)
        
        # åˆå¹¶ã€å»é‡å’Œæ’åºç»“æœ
        all_results = []
        seen_urls = set()
        
        for engine, items in results:
            for item in items:
                url = item["link"]
                if url not in seen_urls:
                    # å¢åŠ å¼•æ“å¤šæ ·æ€§åˆ†æ•°
                    item["score"] += 0.1 * (1 - len(seen_urls)/num_results)
                    all_results.append(item)
                    seen_urls.add(url)
        
        # æŒ‰ç»¼åˆåˆ†æ•°æ’åº
        all_results.sort(key=lambda x: x["score"], reverse=True)
        
        # ç¼“å­˜ç»“æœ
        if self.cache_enabled:
            self.result_cache[cache_key] = all_results
        
        return all_results[:num_results]

    def format_results(self, results: List[Dict], include_source: bool = True) -> str:
        """æ ¼å¼åŒ–æœç´¢ç»“æœç”¨äºæ˜¾ç¤º"""
        if not results:
            return "ğŸ” æ²¡æœ‰æ‰¾åˆ°ç›¸å…³æœç´¢ç»“æœã€‚"
            
        formatted = ["<div class='meta-search-results'>"]
        formatted.append("<h3>ğŸŒ å…ƒæœç´¢ç»“æœ</h3>")
        
        for i, result in enumerate(results, 1):
            formatted.append("<div class='search-result'>")
            if include_source:
                formatted.append(f"<div class='search-source'>{result['source']}</div>")
            formatted.append(f"<a href='{result['link']}' target='_blank' class='search-title'>{result['title']}</a>")
            formatted.append(f"<div class='search-snippet'>{result['snippet']}</div>")
            formatted.append("</div>")
        
        formatted.append("</div>")
        return "\n".join(formatted)

    def get_sources_statistics(self) -> Dict[str, int]:
        """è·å–å„æœç´¢å¼•æ“çš„ç»“æœç»Ÿè®¡"""
        stats = {}
        for cache in self.result_cache.values():
            for item in cache:
                stats[item["source"]] = stats.get(item["source"], 0) + 1
        return stats